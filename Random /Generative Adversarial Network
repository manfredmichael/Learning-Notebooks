{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Generative Adversarial Network","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNO+zycikcB+FETW0/U3kQ9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ep5DpUab08PO","executionInfo":{"status":"ok","timestamp":1633999865729,"user_tz":-420,"elapsed":2857,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["import shutil, os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, losses, optimizers\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cI21QhMj08x5","executionInfo":{"status":"ok","timestamp":1633999866755,"user_tz":-420,"elapsed":1053,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}},"outputId":"8bf0db63-e947-4601-dc01-96125dfcb9a9"},"source":["(X_train, y_train),(X_test, y_test) = tf.keras.datasets.mnist.load_data()\n","images = (np.concatenate((X_train, X_test)).reshape(-1, 28, 28, 1) - 127.5) / 127.5 \n","labels = np.concatenate((y_train, y_test))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"eyWynD6D73nb","executionInfo":{"status":"ok","timestamp":1633999871848,"user_tz":-420,"elapsed":5104,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["BATCH_SIZE = 64\n","STEP_PER_EPOCH = len(images)//BATCH_SIZE"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wbguhi-u5eb2","executionInfo":{"status":"ok","timestamp":1633999872420,"user_tz":-420,"elapsed":303,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["datagen = tf.data.Dataset.from_tensor_slices(images).shuffle(len(images)).batch(64)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ewxbzoLW23F_"},"source":["# Model Definition"]},{"cell_type":"markdown","metadata":{"id":"53WVuZQ-3AFM"},"source":["## Config"]},{"cell_type":"code","metadata":{"id":"9TSvEDen3B4l","executionInfo":{"status":"ok","timestamp":1633999872422,"user_tz":-420,"elapsed":20,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["LATENT_DIM = 100"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-V-o-Djp1lfZ"},"source":["## Discriminator"]},{"cell_type":"code","metadata":{"id":"LsVzDz1f1ZjY","executionInfo":{"status":"ok","timestamp":1633999872423,"user_tz":-420,"elapsed":18,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["def build_discriminator():\n","    discriminator_input = layers.Input(shape=(28, 28, 1))\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(discriminator_input)\n","    x = layers.Dropout(0.3)(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', strides=2, padding='same')(x)\n","    x = layers.Dropout(0.3)(x)\n","    x = layers.Conv2D(256, (3, 3), activation='relu', strides=2, padding='same')(x)\n","    x = layers.Dropout(0.3)(x)\n","    x = layers.Flatten()(x)\n","    \n","    x = layers.Dense(512, activation='relu')(x)\n","    x = layers.Dropout(0.3)(x)\n","    discriminator_output = layers.Dense(1, activation='sigmoid')(x)\n","    \n","    discriminator = models.Model(discriminator_input, discriminator_output)\n","\n","    return discriminator"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVB7718s2Sjv","executionInfo":{"status":"ok","timestamp":1633999872918,"user_tz":-420,"elapsed":507,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}},"outputId":"b3b167ee-f59c-4d27-e8a2-f3f74041aafe"},"source":["discriminator = build_discriminator()\n","discriminator.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 28, 28, 64)        640       \n","_________________________________________________________________\n","dropout (Dropout)            (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 128)       73856     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 7, 7, 256)         295168    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 7, 7, 256)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 12544)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               6423040   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 513       \n","=================================================================\n","Total params: 6,793,217\n","Trainable params: 6,793,217\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"cxQdeStd2XUM"},"source":["## Generator"]},{"cell_type":"code","metadata":{"id":"aXRLPWw82x1Y","executionInfo":{"status":"ok","timestamp":1633999872920,"user_tz":-420,"elapsed":45,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["def build_generator():\n","    latent_input = layers.Input(shape=(LATENT_DIM))\n","    y = layers.Dense(1024, activation='relu', use_bias=False)(latent_input)\n","    y = layers.BatchNormalization()(y)\n","    y = layers.Dense(7 * 7 * 64, activation='relu', use_bias=False)(y)\n","    y = layers.BatchNormalization()(y)\n","    y = layers.Reshape((7, 7 ,64))(y)\n","    y = layers.Conv2DTranspose(256, (3, 3), activation='relu', padding='same', use_bias=False)(y)\n","    y = layers.BatchNormalization()(y)\n","    y = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same', use_bias=False)(y)\n","    y = layers.BatchNormalization()(y)\n","    y = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same', use_bias=False)(y)\n","    y = layers.BatchNormalization()(y)\n","    generator_output = layers.Conv2DTranspose(1, (3, 3), strides=2, activation='tanh', padding='same', use_bias=False)(y)\n","    \n","    generator = models.Model(inputs=[latent_input], outputs=[generator_output])\n","\n","    return generator"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liM9uTXb3W4M","executionInfo":{"status":"ok","timestamp":1633999872921,"user_tz":-420,"elapsed":41,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}},"outputId":"7c21f765-de7a-4228-ffbe-105ac2b24309"},"source":["generator = build_generator()\n","generator.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 100)]             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              102400    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 1024)              4096      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 3136)              3211264   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 3136)              12544     \n","_________________________________________________________________\n","reshape (Reshape)            (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","conv2d_transpose (Conv2DTran (None, 7, 7, 256)         147456    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 7, 7, 256)         1024      \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 7, 7, 128)         294912    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 14, 14, 64)        73728     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n","_________________________________________________________________\n","conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         576       \n","=================================================================\n","Total params: 3,848,768\n","Trainable params: 3,839,552\n","Non-trainable params: 9,216\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"rnqYBGE68pdg"},"source":["## Random Latent"]},{"cell_type":"code","metadata":{"id":"hSdDXARe8rcC","executionInfo":{"status":"ok","timestamp":1633999872924,"user_tz":-420,"elapsed":32,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["def generate_random_latent(batch_size=BATCH_SIZE, latent_dim=LATENT_DIM):\n","    return tf.random.uniform(shape=[batch_size, latent_dim])"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sgmRymZZ3YjC"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"uFIQSnbU3eGv","executionInfo":{"status":"ok","timestamp":1633999872925,"user_tz":-420,"elapsed":31,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["generator_opt = tf.keras.optimizers.Adam(1e-4)\n","discriminator_opt = tf.keras.optimizers.Adam(1e-4)\n","loss_fn = losses.BinaryCrossentropy()"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZbZcJhZA313y"},"source":["## Training Loop"]},{"cell_type":"code","metadata":{"id":"2qE1NpjM4wRy","executionInfo":{"status":"ok","timestamp":1633999872926,"user_tz":-420,"elapsed":27,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["def generate_images(generator, epoch, test_input):\n","  predictions = generator(test_input, training=False)\n","\n","  fig = plt.figure(figsize=(4, 4))\n","\n","  for i in range(predictions.shape[0]):\n","      plt.subplot(4, 4, i+1)\n","      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n","      plt.axis('off')\n","\n","  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n","  plt.show()\n","\n","def progress_bar(iteration, total, size=30):\n","    running = iteration < total\n","    c = \">\" if running else \"=\"\n","    p = (size - 1) * iteration // total\n","    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n","    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n","    return fmt.format(*params)\n","\n","def print_status_bar(iteration, total,  metrics=None):\n","    status = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) \n","                        for m in (metrics or [])])\n","    print(\"\\r{} - \".format(progress_bar(iteration, total)) + status, end=\"\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"2--1vL7335Qg","executionInfo":{"status":"ok","timestamp":1633999872927,"user_tz":-420,"elapsed":27,"user":{"displayName":"Winterfell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ItG0iUtuxF4PcvropQFAl8GBQ7dB8zff1DPn=s64","userId":"10637252633069768208"}}},"source":["def train(generator, discriminator, datagen, generator_opt, discriminator_opt, loss_fn, epochs=50):\n","    metrics = {'discriminator_metrics': tf.keras.metrics.MeanAbsoluteError(name='discriminator_mae'),\n","               'generator_metrics': tf.keras.metrics.MeanAbsoluteError(name='generator_mae')}\n","    for e in range(1, epochs + 1):\n","        generate_images(generator, e, generate_random_latent(16))\n","        print('\\nEpoch {}/{}'.format(e, epochs))\n","        for step, real_img in enumerate(datagen):\n","            with tf.GradientTape(persistent=True) as tape:\n","                fake_img = generator(generate_random_latent(), training=True)\n","                \n","                real_pred = discriminator(real_img, training=True)\n","                fake_pred = discriminator(fake_img, training=True)\n","\n","                discriminator_loss = tf.add_n([loss_fn(tf.ones(tf.shape(real_pred)), real_pred),\n","                                               loss_fn(tf.zeros(tf.shape(fake_pred)), fake_pred)])\n","                \n","                generator_loss = loss_fn(tf.ones(tf.shape(fake_pred)), fake_pred)\n","\n","            gen_gradients = tape.gradient(generator_loss, generator.trainable_variables)\n","            dis_gradients = tape.gradient(discriminator_loss, discriminator.trainable_variables)\n","            generator_opt.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n","            discriminator_opt.apply_gradients(zip(dis_gradients, discriminator.trainable_variables))\n","\n","            del tape\n","\n","            metrics['discriminator_metrics'](tf.ones(tf.shape(real_pred)), real_pred)\n","            metrics['discriminator_metrics'](tf.zeros(tf.shape(fake_pred)), fake_pred)\n","            metrics['generator_metrics'](tf.ones(tf.shape(fake_pred)), fake_pred)\n","\n","            print_status_bar(step, STEP_PER_EPOCH, list(metrics.values()))\n","        for metric in metrics.values():\n","            metric.reset_states()\n","\n","\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVkB-TsSE5m7"},"source":["train(generator, discriminator, datagen, generator_opt, discriminator_opt, loss_fn, epochs=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TWjsBpJYaHlk"},"source":["# Generated Samples"]},{"cell_type":"code","metadata":{"id":"AOLJWki7aK5H"},"source":["def draw_samples(generator, n_samples=10):\n","    latent_samples = generate_random_latent(n_samples * n_samples) \n","    image_samples = generator(latent_samples).numpy()\n","    \n","    image_samples = np.concatenate(image_samples.reshape(n_samples, n_samples * 28, 28), axis=1)\n","    fig = plt.figure(figsize=(20, 20))\n","    plt.axis(False)\n","    plt.tight_layout()\n","    plt.imshow(image_samples, 'gray')\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGr_J9DXaX_o"},"source":["draw_samples(generator, n_samples=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mPqh591QF_pp"},"source":["# Save Model"]},{"cell_type":"code","metadata":{"id":"p029xzbgGDhR"},"source":["generator.save('generator-model')\n","discriminator.save('discriminator-model')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tiU4vMb_bzrV"},"source":["# Fine Tune for Classification"]},{"cell_type":"code","metadata":{"id":"rndbzSdab2y6"},"source":["X_train_norm = (X_train.reshape(-1, 28, 28, 1) - 127.5) / 127.5\n","X_test_norm = (X_test.reshape(-1, 28, 28, 1) - 127.5) / 127.5\n","\n","train_generator = tf.data.Dataset.from_tensor_slices((X_train_norm, y_train)).shuffle(len(X_train)).batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzxdlYHtc4Ty"},"source":["discriminator.layers[:-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWl-d0leccYb"},"source":["model = models.Sequential(discriminator.layers[:-3])\n","\n","for layer in model.layers:\n","    layer.trainable=False\n","\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","\n","model.compile(optimizer=optimizers.Adam(),\n","              loss=losses.SparseCategoricalCrossentropy(),\n","              metrics=['accuracy', 'mse'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tuXWhTmdn7i"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pR5UiLBgd2y7"},"source":["model.fit(train_generator, epochs=30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8UhM8G4ee2i"},"source":["model.evaluate(X_test_norm, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3oSNqIpXtido"},"source":["# Generating Fashion MNIST"]},{"cell_type":"code","metadata":{"id":"7zfajGxBtzQ8"},"source":["(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = tf.keras.datasets.fashion_mnist.load_data()\n","fashion_images = (np.concatenate((X_train_fashion, X_test_fashion)).reshape(-1, 28, 28, 1) - 127.5) / 127.5 \n","fashion_labels = np.concatenate((y_train_fashion, y_test_fashion))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZcDlDUSxP9E"},"source":["BATCH_SIZE = 256\n","STEP_PER_EPOCH = len(fashion_images)//BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kcR2z1UuBlM"},"source":["fashion_datagen = tf.data.Dataset.from_tensor_slices(fashion_images).shuffle(len(fashion_images)).batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WlvtNXWIw0q0"},"source":["fashion_generator = build_generator()\n","fashion_discriminator = build_discriminator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0djw0v9HuW-v"},"source":["train(fashion_generator, fashion_discriminator, fashion_datagen, generator_opt, discriminator_opt, loss_fn, epochs=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SU8HdluiBu9Y"},"source":["draw_samples(fashion_generator, n_samples=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lBxoU0r_czr_"},"source":["# Generating Human Faces"]},{"cell_type":"markdown","metadata":{"id":"RqiKFLDwdHGb"},"source":["## Download Dataset"]},{"cell_type":"code","metadata":{"id":"oKxexFNqc9O5"},"source":["!wget http://vision.ucsd.edu/datasets/yale_face_dataset_original/yalefaces.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OB5_ni9BdVhr"},"source":["from zipfile import ZipFile\n","\n","DATA_PATH = './yalefaces'\n","\n","with ZipFile('./yalefaces.zip') as z:\n","    z.extractall()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zn7eh-P3dTle"},"source":["os.remove(os.join(DATA_PATH, 'Readme.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"vcl_bGbxjNtr"},"source":["train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  DATA_PATH,\n","  batch_size=BATCH_SI)\n"],"execution_count":null,"outputs":[]}]}