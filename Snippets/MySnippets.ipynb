{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MySnippets","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNVG894VfQcw9K51auViaQp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LRXBGRwCfR-n"},"source":["#1Cycle Scheduler"]},{"cell_type":"code","metadata":{"id":"cELGzijHfZ7n"},"source":["#from tensorflow import keras\n","#K = keras.backend\n","\n","class OneCycleScheduler(keras.callbacks.Callback):\n","    def __init__(self, iterations, max_rate, start_rate=None,\n","                 last_iterations=None, last_rate=None):\n","        self.iterations = iterations\n","        self.max_rate = max_rate\n","        self.start_rate = start_rate or max_rate / 10\n","        self.last_iterations = last_iterations or iterations // 10 + 1\n","        self.half_iteration = (iterations - self.last_iterations) // 2\n","        self.last_rate = last_rate or self.start_rate / 1000\n","        self.iteration = 0\n","    def _interpolate(self, iter1, iter2, rate1, rate2):\n","        return ((rate2 - rate1) * (self.iteration - iter1)\n","                / (iter2 - iter1) + rate1)\n","    def on_batch_begin(self, batch, logs):\n","        if self.iteration < self.half_iteration:\n","            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n","        elif self.iteration < 2 * self.half_iteration:\n","            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n","                                     self.max_rate, self.start_rate)\n","        else:\n","            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n","                                     self.start_rate, self.last_rate)\n","        self.iteration += 1\n","        K.set_value(self.model.optimizer.lr, rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XuNcLqAikjBq"},"source":["# Tensorflow Import"]},{"cell_type":"code","metadata":{"id":"NaSik4mAkt_f"},"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cZl6TMH1lED_"},"source":["# Find Learning Rate"]},{"cell_type":"code","metadata":{"id":"1TEiHo2ilRyw"},"source":["#import matplotlib.pyplot as plt\n","#from tensorflow import keras\n","\n","K = keras.backend\n","\n","class ExponentialLearningRate(keras.callbacks.Callback):\n","    def __init__(self, factor):\n","        self.factor = factor\n","        self.rates = []\n","        self.losses = []\n","    def on_batch_end(self, batch, logs):\n","        self.rates.append(K.get_value(self.model.optimizer.lr))\n","        self.losses.append(logs[\"loss\"])\n","        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n","\n","def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n","    init_weights = model.get_weights()\n","    iterations = math.ceil(len(X) / batch_size) * epochs\n","    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n","    init_lr = K.get_value(model.optimizer.lr)\n","    K.set_value(model.optimizer.lr, min_rate)\n","    exp_lr = ExponentialLearningRate(factor)\n","    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n","                        callbacks=[exp_lr])\n","    K.set_value(model.optimizer.lr, init_lr)\n","    model.set_weights(init_weights)\n","    return exp_lr.rates, exp_lr.losses\n","\n","def plot_lr_vs_loss(rates, losses):\n","    plt.plot(rates, losses)\n","    plt.gca().set_xscale('log')\n","    plt.hlines(min(losses), min(rates), max(rates))\n","    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n","    plt.xlabel(\"Learning rate\")\n","    plt.ylabel(\"Loss\") \n","    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TAufayx-lfit"},"source":["# VGG BLock"]},{"cell_type":"code","metadata":{"id":"H5vJNQohltth"},"source":["model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8So3vRwol2qF"},"source":["# Tensorboard"]},{"cell_type":"code","metadata":{"id":"NyDC4wESmDLJ"},"source":["import datetime, os\n","\n","%load_ext tensorboard\n","\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wxm4c5iPnP75"},"source":["# Huber Loss"]},{"cell_type":"code","metadata":{"id":"IstympGanuNo"},"source":["#from tensorflow import keras\n","\n","class HuberLoss(keras.losses.Loss):\n","    def __init__(self, threshold=1.0, **kwargs):\n","        self.threshold = threshold\n","        super().__init__(**kwargs)\n","    def call(self, y_true, y_pred):\n","        error = y_true - y_pred\n","        is_small_error = tf.abs(error) < self.threshold\n","        squarred_loss = tf.squared(error)/2\n","        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n","        return tf.where(is_small_error, squared_loss, linear_loss)\n","    def get_config(self):\n","        base_config = super().get_config()\n","        return {**base_config, 'threshold': self.threshold}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pI4Pbr0YpdF1"},"source":["# Custom Layer"]},{"cell_type":"code","metadata":{"id":"hRZexIj3pmWY"},"source":["#import tensorflow as keras \n","#from tensorflow.keras import layers\n","\n","class MyDense(keras.layers.Layer):\n","\n","    def __init__(self, units, activation=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.units = units\n","        self.activation = keras.activations.get(activation)\n","    \n","    def build(self, batch_input_shape):\n","        self.kernel = self.add_weight(name=\"kernel\", \n","                                      shape=[batch_input_shape[-1], self.units],\n","                                      initializer=\"glorot_normal\")\n","        self.bias = self.add_weight(name=\"bias\", \n","                                    shape=[self.units], \n","                                    initializer=\"zeros\")\n","        super().build(batch_input_shape) # must be at the end\n","\n","    def call(self, X):\n","        return self.activation(X @ self.kernel + self.bias)\n","\n","    def compute_output_shape(self, batch_input_shape):\n","        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n","\n","    def get_config(self):\n","        base_config = super().get_config()\n","        return {**base_config, 'units': self.units, \n","                'activation': keras.activations.serialize(self.activation)}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FGstPc3mmos4"},"source":["# Kaggle Dataset"]},{"cell_type":"code","metadata":{"id":"mcJo4jFsmqYM"},"source":["import os\n","\n","if not os.path.isdir('~/.kaggle'):\n","    os.makedirs('~/.kaggle')\n","\n","!mv kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","!kaggle datasets download -d aruchomu/data-for-yolo-v3-kerne"],"execution_count":null,"outputs":[]}]}